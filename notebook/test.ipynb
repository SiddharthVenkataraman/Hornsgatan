{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46dadb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"81pt\" height=\"58pt\"\n",
       " viewBox=\"0.00 0.00 81.00 58.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 54)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-54 77,-54 77,4 -4,4\"/>\n",
       "<!-- default -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>default</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"67,-50 0,-50 0,0 73,0 73,-44 67,-50\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"67,-50 67,-44 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"73,-44 67,-44 \"/>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-35.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">default</text>\n",
       "<text text-anchor=\"start\" x=\"21\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x730129d876a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from hamilton.function_modifiers import config, extract_columns\n",
    "\n",
    "\n",
    "@extract_columns(\"spend\", \"signups\")\n",
    "@config.when(default=\"True\")\n",
    "def default_data() -> pd.DataFrame:\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"signups\": pd.Series([1, 10, 50, 100, 200, 400]),\n",
    "            \"spend\": pd.Series([10, 10, 20, 40, 40, 50]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def avg_3wk_spend(spend: pd.Series) -> pd.Series:\n",
    "    \"\"\"Rolling 3 week average spend.\"\"\"\n",
    "    return spend.rolling(3).mean()\n",
    "\n",
    "\n",
    "def spend_per_signup(spend: pd.Series, signups: pd.Series) -> pd.Series:\n",
    "    \"\"\"The cost per signup in relation to spend.\"\"\"\n",
    "    return spend / signups\n",
    "\n",
    "\n",
    "def spend_mean(spend: pd.Series) -> float:\n",
    "    \"\"\"Shows function creating a scalar. In this case it computes the mean of the entire column.\"\"\"\n",
    "    return spend.mean()\n",
    "\n",
    "\n",
    "def spend_zero_mean(spend: pd.Series, spend_mean: float) -> pd.Series:\n",
    "    \"\"\"Shows function that takes a scalar. In this case to zero mean spend.\"\"\"\n",
    "    return spend - spend_mean\n",
    "\n",
    "\n",
    "def spend_std_dev(spend: pd.Series) -> float:\n",
    "    \"\"\"Function that computes the standard deviation of the spend column.\"\"\"\n",
    "    return spend.std()\n",
    "\n",
    "\n",
    "def spend_zero_mean_unit_variance(spend_zero_mean: pd.Series, spend_std_dev: float) -> pd.Series:\n",
    "    \"\"\"Function showing one way to make spend have zero mean and unit variance.\"\"\"\n",
    "    return spend_zero_mean / spend_std_dev\n",
    "\n",
    "\n",
    "\n",
    "from hamilton import base, driver\n",
    "\n",
    "dr = driver.Driver(\n",
    "    {\"default\": \"True\"},\n",
    "   # hello_world,\n",
    "    adapter=base.DefaultAdapter(),\n",
    ")\n",
    "# create the DAG image\n",
    "dr.display_all_functions(\"dag\", {\"format\": \"png\", \"view\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9057ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "947db25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"1056pt\" height=\"449pt\"\n",
       " viewBox=\"0.00 0.00 1056.00 449.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 445)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-445 1052,-445 1052,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster__legend</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"46,-302 46,-433 142,-433 142,-302 46,-302\"/>\n",
       "<text text-anchor=\"middle\" x=\"94\" y=\"-417.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Legend</text>\n",
       "</g>\n",
       "<!-- default -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>default</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"124.5,-210 57.5,-210 57.5,-160 130.5,-160 130.5,-204 124.5,-210\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"124.5,-210 124.5,-204 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"130.5,-204 124.5,-204 \"/>\n",
       "<text text-anchor=\"start\" x=\"65.5\" y=\"-195.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">default</text>\n",
       "<text text-anchor=\"start\" x=\"78.5\" y=\"-167.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- spend -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>spend</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M347.5,-247C347.5,-247 235.5,-247 235.5,-247 229.5,-247 223.5,-241 223.5,-235 223.5,-235 223.5,-195 223.5,-195 223.5,-189 229.5,-183 235.5,-183 235.5,-183 347.5,-183 347.5,-183 353.5,-183 359.5,-189 359.5,-195 359.5,-195 359.5,-235 359.5,-235 359.5,-241 353.5,-247 347.5,-247\"/>\n",
       "<text text-anchor=\"start\" x=\"234.5\" y=\"-225.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">spend: default</text>\n",
       "<text text-anchor=\"start\" x=\"270\" y=\"-197.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">Series</text>\n",
       "</g>\n",
       "<!-- spend_per_signup -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>spend_per_signup</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M544,-348C544,-348 407,-348 407,-348 401,-348 395,-342 395,-336 395,-336 395,-296 395,-296 395,-290 401,-284 407,-284 407,-284 544,-284 544,-284 550,-284 556,-290 556,-296 556,-296 556,-336 556,-336 556,-342 550,-348 544,-348\"/>\n",
       "<text text-anchor=\"start\" x=\"406\" y=\"-326.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">spend_per_signup</text>\n",
       "<text text-anchor=\"start\" x=\"454\" y=\"-298.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">Series</text>\n",
       "</g>\n",
       "<!-- spend&#45;&gt;spend_per_signup -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>spend&#45;&gt;spend_per_signup</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M350.34,-247.1C368.67,-257.27 389.08,-268.59 407.97,-279.08\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"406.37,-282.2 416.81,-283.99 409.77,-276.07 406.37,-282.2\"/>\n",
       "</g>\n",
       "<!-- spend_zero_mean -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>spend_zero_mean</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M734,-146C734,-146 597,-146 597,-146 591,-146 585,-140 585,-134 585,-134 585,-94 585,-94 585,-88 591,-82 597,-82 597,-82 734,-82 734,-82 740,-82 746,-88 746,-94 746,-94 746,-134 746,-134 746,-140 740,-146 734,-146\"/>\n",
       "<text text-anchor=\"start\" x=\"596\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">spend_zero_mean</text>\n",
       "<text text-anchor=\"start\" x=\"644\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">Series</text>\n",
       "</g>\n",
       "<!-- spend&#45;&gt;spend_zero_mean -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>spend&#45;&gt;spend_zero_mean</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M359.72,-238.14C414.89,-253.11 493.76,-265.09 556,-237 593.16,-220.23 622.7,-183.74 641.51,-154.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"644.62,-156.46 647,-146.14 638.7,-152.72 644.62,-156.46\"/>\n",
       "</g>\n",
       "<!-- avg_3wk_spend -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>avg_3wk_spend</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M535,-228C535,-228 416,-228 416,-228 410,-228 404,-222 404,-216 404,-216 404,-176 404,-176 404,-170 410,-164 416,-164 416,-164 535,-164 535,-164 541,-164 547,-170 547,-176 547,-176 547,-216 547,-216 547,-222 541,-228 535,-228\"/>\n",
       "<text text-anchor=\"start\" x=\"415\" y=\"-206.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">avg_3wk_spend</text>\n",
       "<text text-anchor=\"start\" x=\"454\" y=\"-178.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">Series</text>\n",
       "</g>\n",
       "<!-- spend&#45;&gt;avg_3wk_spend -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>spend&#45;&gt;avg_3wk_spend</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M359.75,-207.98C370.87,-206.82 382.5,-205.6 393.91,-204.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"394.28,-207.89 403.86,-203.37 393.55,-200.93 394.28,-207.89\"/>\n",
       "</g>\n",
       "<!-- spend_mean -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>spend_mean</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M523.5,-146C523.5,-146 427.5,-146 427.5,-146 421.5,-146 415.5,-140 415.5,-134 415.5,-134 415.5,-94 415.5,-94 415.5,-88 421.5,-82 427.5,-82 427.5,-82 523.5,-82 523.5,-82 529.5,-82 535.5,-88 535.5,-94 535.5,-94 535.5,-134 535.5,-134 535.5,-140 529.5,-146 523.5,-146\"/>\n",
       "<text text-anchor=\"start\" x=\"426.5\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">spend_mean</text>\n",
       "<text text-anchor=\"start\" x=\"460\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">float</text>\n",
       "</g>\n",
       "<!-- spend&#45;&gt;spend_mean -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>spend&#45;&gt;spend_mean</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M346.18,-182.85C361.83,-173.68 379.01,-163.79 395,-155 398.67,-152.98 402.46,-150.93 406.29,-148.88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"408.08,-151.89 415.27,-144.1 404.8,-145.7 408.08,-151.89\"/>\n",
       "</g>\n",
       "<!-- spend_std_dev -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>spend_std_dev</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M532,-64C532,-64 419,-64 419,-64 413,-64 407,-58 407,-52 407,-52 407,-12 407,-12 407,-6 413,0 419,0 419,0 532,0 532,0 538,0 544,-6 544,-12 544,-12 544,-52 544,-52 544,-58 538,-64 532,-64\"/>\n",
       "<text text-anchor=\"start\" x=\"418\" y=\"-42.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">spend_std_dev</text>\n",
       "<text text-anchor=\"start\" x=\"460\" y=\"-14.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">float</text>\n",
       "</g>\n",
       "<!-- spend&#45;&gt;spend_std_dev -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>spend&#45;&gt;spend_std_dev</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M309.72,-182.87C327.7,-151.68 358.37,-104.54 395,-73 396.14,-72.02 397.31,-71.05 398.5,-70.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"400.71,-72.82 406.67,-64.06 396.55,-67.19 400.71,-72.82\"/>\n",
       "</g>\n",
       "<!-- spend_zero_mean_unit_variance -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>spend_zero_mean_unit_variance</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M1036,-105C1036,-105 787,-105 787,-105 781,-105 775,-99 775,-93 775,-93 775,-53 775,-53 775,-47 781,-41 787,-41 787,-41 1036,-41 1036,-41 1042,-41 1048,-47 1048,-53 1048,-53 1048,-93 1048,-93 1048,-99 1042,-105 1036,-105\"/>\n",
       "<text text-anchor=\"start\" x=\"786\" y=\"-83.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">spend_zero_mean_unit_variance</text>\n",
       "<text text-anchor=\"start\" x=\"890\" y=\"-55.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">Series</text>\n",
       "</g>\n",
       "<!-- spend_zero_mean&#45;&gt;spend_zero_mean_unit_variance -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>spend_zero_mean&#45;&gt;spend_zero_mean_unit_variance</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M746.06,-100.63C752.17,-99.6 758.45,-98.55 764.82,-97.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"765.6,-100.9 774.88,-95.79 764.44,-93.99 765.6,-100.9\"/>\n",
       "</g>\n",
       "<!-- spend_mean&#45;&gt;spend_zero_mean -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>spend_mean&#45;&gt;spend_zero_mean</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M535.73,-114C548.16,-114 561.54,-114 574.81,-114\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"574.92,-117.5 584.92,-114 574.92,-110.5 574.92,-117.5\"/>\n",
       "</g>\n",
       "<!-- default_data -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>default_data</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M176,-292C176,-292 12,-292 12,-292 6,-292 0,-286 0,-280 0,-280 0,-240 0,-240 0,-234 6,-228 12,-228 12,-228 176,-228 176,-228 182,-228 188,-234 188,-240 188,-240 188,-280 188,-280 188,-286 182,-292 176,-292\"/>\n",
       "<text text-anchor=\"start\" x=\"11\" y=\"-270.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">default_data: default</text>\n",
       "<text text-anchor=\"start\" x=\"56\" y=\"-242.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">DataFrame</text>\n",
       "</g>\n",
       "<!-- default_data&#45;&gt;spend -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>default_data&#45;&gt;spend</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M188.17,-238.55C196.63,-236.61 205.14,-234.65 213.43,-232.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"214.47,-236.09 223.43,-230.44 212.9,-229.27 214.47,-236.09\"/>\n",
       "</g>\n",
       "<!-- signups -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>signups</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M354,-338C354,-338 229,-338 229,-338 223,-338 217,-332 217,-326 217,-326 217,-286 217,-286 217,-280 223,-274 229,-274 229,-274 354,-274 354,-274 360,-274 366,-280 366,-286 366,-286 366,-326 366,-326 366,-332 360,-338 354,-338\"/>\n",
       "<text text-anchor=\"start\" x=\"228\" y=\"-316.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">signups: default</text>\n",
       "<text text-anchor=\"start\" x=\"270\" y=\"-288.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">Series</text>\n",
       "</g>\n",
       "<!-- default_data&#45;&gt;signups -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>default_data&#45;&gt;signups</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M188.17,-281.92C194.49,-283.41 200.84,-284.9 207.11,-286.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206.35,-289.8 216.89,-288.68 207.95,-282.98 206.35,-289.8\"/>\n",
       "</g>\n",
       "<!-- spend_std_dev&#45;&gt;spend_zero_mean_unit_variance -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>spend_std_dev&#45;&gt;spend_zero_mean_unit_variance</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M544.31,-38.41C603.18,-43.97 690.43,-52.21 765,-59.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"764.68,-62.74 774.96,-60.2 765.34,-55.77 764.68,-62.74\"/>\n",
       "</g>\n",
       "<!-- signups&#45;&gt;spend_per_signup -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>signups&#45;&gt;spend_per_signup</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M366,-310.04C372.07,-310.37 378.24,-310.71 384.41,-311.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"384.59,-314.57 394.77,-311.62 384.98,-307.58 384.59,-314.57\"/>\n",
       "</g>\n",
       "<!-- config -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>config</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"117.5,-402 64.5,-402 64.5,-366 123.5,-366 123.5,-396 117.5,-402\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"117.5,-402 117.5,-396 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"123.5,-396 117.5,-396 \"/>\n",
       "<text text-anchor=\"middle\" x=\"94\" y=\"-380.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">config</text>\n",
       "</g>\n",
       "<!-- function -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>function</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M122,-347.5C122,-347.5 66,-347.5 66,-347.5 60,-347.5 54,-341.5 54,-335.5 54,-335.5 54,-322.5 54,-322.5 54,-316.5 60,-310.5 66,-310.5 66,-310.5 122,-310.5 122,-310.5 128,-310.5 134,-316.5 134,-322.5 134,-322.5 134,-335.5 134,-335.5 134,-341.5 128,-347.5 122,-347.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"94\" y=\"-325.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">function</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x730129db9cc0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hamilton import dataflows, driver\n",
    "hello_world = dataflows.import_module(\"hello_world\", \"skrawcz\")\n",
    "\n",
    "dr = driver.Driver(\n",
    "    {\"default\": \"True\"},\n",
    "    hello_world,\n",
    "    adapter=base.DefaultAdapter(),\n",
    ")\n",
    "# create the DAG image\n",
    "dr.display_all_functions(\"dag\", {\"format\": \"png\", \"view\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "026d5b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   spend  signups  avg_3wk_spend  spend_per_signup  spend_zero_mean  spend_zero_mean_unit_variance\n",
      "0     10        1            NaN            10.000       -18.333333                      -1.064405\n",
      "1     10       10            NaN             1.000       -18.333333                      -1.064405\n",
      "2     20       50      13.333333             0.400        -8.333333                      -0.483821\n",
      "3     40      100      23.333333             0.400        11.666667                       0.677349\n",
      "4     40      200      33.333333             0.200        11.666667                       0.677349\n",
      "5     50      400      43.333333             0.125        21.666667                       1.257934\n"
     ]
    }
   ],
   "source": [
    "from hamilton import dataflows, driver\n",
    "# downloads into ~/.hamilton/dataflows and loads the module -- WARNING: ensure you know what code you're importing!\n",
    "hello_world = dataflows.import_module(\"hello_world\", \"skrawcz\")\n",
    "\n",
    "# Create the driver -- passing in the functions module \n",
    "# and the right adapter for the result - in this case a Pandas DataFrame\n",
    "default_df = hello_world.default_data()\n",
    "\n",
    "dr = (\n",
    "  driver.Builder()\n",
    "    .with_modules(hello_world)\n",
    "    .with_adapters(base.PandasDataFrameResult())\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Execute the driver -- first argument is final variables\n",
    "# As well as inputs (loaded above )\n",
    "df = dr.execute(\n",
    "  [\n",
    "    \"spend\", \n",
    "    \"signups\", \n",
    "    \"avg_3wk_spend\", \n",
    "    \"spend_per_signup\", \n",
    "    \"spend_zero_mean\", \n",
    "    \"spend_zero_mean_unit_variance\"],\n",
    "    inputs={\"spend\": default_df[\"spend\"], \"signups\": default_df[\"signups\"]},\n",
    "  # uncomment the following to short circuit graph computation and override the value for spend_mean\n",
    "  #, overrides={\"spend_mean\": 100.0}  \n",
    ")\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e727b6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spend': 0    10\n",
       " 1    10\n",
       " 2    20\n",
       " 3    40\n",
       " 4    40\n",
       " 5    50\n",
       " Name: spend, dtype: int64,\n",
       " 'signups': 0      1\n",
       " 1     10\n",
       " 2     50\n",
       " 3    100\n",
       " 4    200\n",
       " 5    400\n",
       " Name: signups, dtype: int64,\n",
       " 'avg_3wk_spend': 0          NaN\n",
       " 1          NaN\n",
       " 2    13.333333\n",
       " 3    23.333333\n",
       " 4    33.333333\n",
       " 5    43.333333\n",
       " Name: spend, dtype: float64,\n",
       " 'spend_per_signup': 0    10.000\n",
       " 1     1.000\n",
       " 2     0.400\n",
       " 3     0.400\n",
       " 4     0.200\n",
       " 5     0.125\n",
       " dtype: float64,\n",
       " 'spend_zero_mean': 0   -18.333333\n",
       " 1   -18.333333\n",
       " 2    -8.333333\n",
       " 3    11.666667\n",
       " 4    11.666667\n",
       " 5    21.666667\n",
       " Name: spend, dtype: float64,\n",
       " 'spend_zero_mean_unit_variance': 0   -1.064405\n",
       " 1   -1.064405\n",
       " 2   -0.483821\n",
       " 3    0.677349\n",
       " 4    0.677349\n",
       " 5    1.257934\n",
       " Name: spend, dtype: float64}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hamilton import dataflows, driver\n",
    "# downloads into ~/.hamilton/dataflows and loads the module -- WARNING: ensure you know what code you're importing!\n",
    "hello_world = dataflows.import_module(\"hello_world\", \"skrawcz\")\n",
    "\n",
    "# Create the driver -- passing in the functions module \n",
    "# and the right adapter for the result - in this case a Pandas DataFrame\n",
    "\n",
    "dr = driver.Driver(\n",
    "    {\"default\": \"True\"},\n",
    "    hello_world,\n",
    "\n",
    "   # hello_world,\n",
    "    adapter=base.DefaultAdapter(),\n",
    ")\n",
    "\n",
    "# Execute the driver -- first argument is final variables\n",
    "# As well as inputs (loaded above )\n",
    "df = dr.execute(\n",
    "  [\n",
    "    \"spend\", \n",
    "    \"signups\", \n",
    "    \"avg_3wk_spend\", \n",
    "    \"spend_per_signup\", \n",
    "    \"spend_zero_mean\", \n",
    "    \"spend_zero_mean_unit_variance\"],\n",
    "  # uncomment the following to short circuit graph computation and override the value for spend_mean\n",
    "  #, overrides={\"spend_mean\": 100.0}  \n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69f7a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hamilton import dataflows, driver\n",
    "# downloads into ~/.hamilton/dataflows and loads the module -- WARNING: ensure you know what code you're importing!\n",
    "hello_world = dataflows.import_module(\"hello_world\", \"skrawcz\")\n",
    "\n",
    "# Create the driver -- passing in the functions module \n",
    "# and the right adapter for the result - in this case a Pandas DataFrame\n",
    "default_df = hello_world.default_data()\n",
    "# Create the driver \n",
    "dr = driver.Builder().with_modules(hello_world).build()\n",
    "\n",
    "# Display the whole graph\n",
    "gr = dr.display_all_functions(\n",
    "  # \"graph.png\", # create image if running locally\n",
    "  show_legend=True,\n",
    "  orient=\"LR\",\n",
    "  deduplicate_inputs=True,\n",
    ")\n",
    "gr  # Display the graph directly in the Jupyter Notebook\n",
    "#wasm_display(gr) # helper to display graph on this page\n",
    "# Save as raw SVG\n",
    "svg_content = gr.pipe(format='svg').decode('utf-8')\n",
    "\n",
    "# Wrap in HTML\n",
    "html_content = f\"\"\"\n",
    "<html>\n",
    "  <body>\n",
    "    {svg_content}\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "with open(\"graph.html\", \"w\") as f:\n",
    "    f.write(html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94659cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"1161pt\" height=\"348pt\"\n",
       " viewBox=\"0.00 0.00 1161.00 348.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 344)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-344 1157,-344 1157,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster__legend</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"26,-64 26,-196 122,-196 122,-64 26,-64\"/>\n",
       "<text text-anchor=\"middle\" x=\"74\" y=\"-180.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Legend</text>\n",
       "</g>\n",
       "<!-- node_id -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>node_id</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M455.5,-258C455.5,-258 396.5,-258 396.5,-258 390.5,-258 384.5,-252 384.5,-246 384.5,-246 384.5,-206 384.5,-206 384.5,-200 390.5,-194 396.5,-194 396.5,-194 455.5,-194 455.5,-194 461.5,-194 467.5,-200 467.5,-206 467.5,-206 467.5,-246 467.5,-246 467.5,-252 461.5,-258 455.5,-258\"/>\n",
       "<text text-anchor=\"start\" x=\"395.5\" y=\"-236.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">node_id</text>\n",
       "<text text-anchor=\"start\" x=\"404.5\" y=\"-208.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">Series</text>\n",
       "</g>\n",
       "<!-- detector_id -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>detector_id</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M645.5,-258C645.5,-258 558.5,-258 558.5,-258 552.5,-258 546.5,-252 546.5,-246 546.5,-246 546.5,-206 546.5,-206 546.5,-200 552.5,-194 558.5,-194 558.5,-194 645.5,-194 645.5,-194 651.5,-194 657.5,-200 657.5,-206 657.5,-206 657.5,-246 657.5,-246 657.5,-252 651.5,-258 645.5,-258\"/>\n",
       "<text text-anchor=\"start\" x=\"557.5\" y=\"-236.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">detector_id</text>\n",
       "<text text-anchor=\"start\" x=\"580.5\" y=\"-208.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">Series</text>\n",
       "</g>\n",
       "<!-- node_id&#45;&gt;detector_id -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>node_id&#45;&gt;detector_id</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M467.8,-226C488.18,-226 513.34,-226 536.28,-226\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"536.3,-229.5 546.3,-226 536.3,-222.5 536.3,-229.5\"/>\n",
       "</g>\n",
       "<!-- save_transform_raw_data -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>save_transform_raw_data</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M1141,-64C1141,-64 942,-64 942,-64 936,-64 930,-58 930,-52 930,-52 930,-12 930,-12 930,-6 936,0 942,0 942,0 1141,0 1141,0 1147,0 1153,-6 1153,-12 1153,-12 1153,-52 1153,-52 1153,-58 1147,-64 1141,-64\"/>\n",
       "<text text-anchor=\"start\" x=\"941\" y=\"-42.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">save_transform_raw_data</text>\n",
       "<text text-anchor=\"start\" x=\"1032\" y=\"-14.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">str</text>\n",
       "</g>\n",
       "<!-- transform_raw_data -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>transform_raw_data</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M889,-161C889,-161 734,-161 734,-161 728,-161 722,-155 722,-149 722,-149 722,-109 722,-109 722,-103 728,-97 734,-97 734,-97 889,-97 889,-97 895,-97 901,-103 901,-109 901,-109 901,-149 901,-149 901,-155 895,-161 889,-161\"/>\n",
       "<text text-anchor=\"start\" x=\"733\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">transform_raw_data</text>\n",
       "<text text-anchor=\"start\" x=\"773.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">DataFrame</text>\n",
       "</g>\n",
       "<!-- detector_id&#45;&gt;transform_raw_data -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>detector_id&#45;&gt;transform_raw_data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M657.8,-201.22C669.44,-195.9 681.64,-190.29 693,-185 706.53,-178.7 720.89,-171.92 734.76,-165.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"736.27,-168.49 743.8,-161.04 733.26,-162.17 736.27,-168.49\"/>\n",
       "</g>\n",
       "<!-- read_raw_data -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>read_raw_data</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M315.5,-135C315.5,-135 202.5,-135 202.5,-135 196.5,-135 190.5,-129 190.5,-123 190.5,-123 190.5,-83 190.5,-83 190.5,-77 196.5,-71 202.5,-71 202.5,-71 315.5,-71 315.5,-71 321.5,-71 327.5,-77 327.5,-83 327.5,-83 327.5,-123 327.5,-123 327.5,-129 321.5,-135 315.5,-135\"/>\n",
       "<text text-anchor=\"start\" x=\"201.5\" y=\"-113.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">read_raw_data</text>\n",
       "<text text-anchor=\"start\" x=\"221\" y=\"-85.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">DataFrame</text>\n",
       "</g>\n",
       "<!-- read_raw_data&#45;&gt;node_id -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>read_raw_data&#45;&gt;node_id</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M303.35,-135.32C325.72,-151.99 353.08,-172.39 376.18,-189.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"374.38,-192.63 384.49,-195.8 378.56,-187.02 374.38,-192.63\"/>\n",
       "</g>\n",
       "<!-- avg_speed -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>avg_speed</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M466.5,-176C466.5,-176 385.5,-176 385.5,-176 379.5,-176 373.5,-170 373.5,-164 373.5,-164 373.5,-124 373.5,-124 373.5,-118 379.5,-112 385.5,-112 385.5,-112 466.5,-112 466.5,-112 472.5,-112 478.5,-118 478.5,-124 478.5,-124 478.5,-164 478.5,-164 478.5,-170 472.5,-176 466.5,-176\"/>\n",
       "<text text-anchor=\"start\" x=\"384.5\" y=\"-154.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">avg_speed</text>\n",
       "<text text-anchor=\"start\" x=\"404.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">Series</text>\n",
       "</g>\n",
       "<!-- read_raw_data&#45;&gt;avg_speed -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>read_raw_data&#45;&gt;avg_speed</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M327.59,-119.79C339.55,-122.77 351.94,-125.85 363.71,-128.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"362.88,-132.17 373.43,-131.19 364.57,-125.38 362.88,-132.17\"/>\n",
       "</g>\n",
       "<!-- timestamp -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>timestamp</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M467.5,-94C467.5,-94 384.5,-94 384.5,-94 378.5,-94 372.5,-88 372.5,-82 372.5,-82 372.5,-42 372.5,-42 372.5,-36 378.5,-30 384.5,-30 384.5,-30 467.5,-30 467.5,-30 473.5,-30 479.5,-36 479.5,-42 479.5,-42 479.5,-82 479.5,-82 479.5,-88 473.5,-94 467.5,-94\"/>\n",
       "<text text-anchor=\"start\" x=\"383.5\" y=\"-72.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">timestamp</text>\n",
       "<text text-anchor=\"start\" x=\"404.5\" y=\"-44.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">Series</text>\n",
       "</g>\n",
       "<!-- read_raw_data&#45;&gt;timestamp -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>read_raw_data&#45;&gt;timestamp</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M327.59,-86.21C339.15,-83.33 351.12,-80.36 362.54,-77.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"363.56,-80.87 372.42,-75.07 361.87,-74.08 363.56,-80.87\"/>\n",
       "</g>\n",
       "<!-- sensor_info -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>sensor_info</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M470,-340C470,-340 382,-340 382,-340 376,-340 370,-334 370,-328 370,-328 370,-288 370,-288 370,-282 376,-276 382,-276 382,-276 470,-276 470,-276 476,-276 482,-282 482,-288 482,-288 482,-328 482,-328 482,-334 476,-340 470,-340\"/>\n",
       "<text text-anchor=\"start\" x=\"381\" y=\"-318.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">sensor_info</text>\n",
       "<text text-anchor=\"start\" x=\"388\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">DataFrame</text>\n",
       "</g>\n",
       "<!-- sensor_info&#45;&gt;detector_id -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>sensor_info&#45;&gt;detector_id</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M482.05,-282.05C499.52,-273.82 518.98,-264.65 537.02,-256.15\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"538.75,-259.21 546.3,-251.78 535.77,-252.87 538.75,-259.21\"/>\n",
       "</g>\n",
       "<!-- split_and_save_daily -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>split_and_save_daily</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M1119.5,-161C1119.5,-161 963.5,-161 963.5,-161 957.5,-161 951.5,-155 951.5,-149 951.5,-149 951.5,-109 951.5,-109 951.5,-103 957.5,-97 963.5,-97 963.5,-97 1119.5,-97 1119.5,-97 1125.5,-97 1131.5,-103 1131.5,-109 1131.5,-109 1131.5,-149 1131.5,-149 1131.5,-155 1125.5,-161 1119.5,-161\"/>\n",
       "<text text-anchor=\"start\" x=\"962.5\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">split_and_save_daily</text>\n",
       "<text text-anchor=\"start\" x=\"1031\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">list</text>\n",
       "</g>\n",
       "<!-- time_detector_real -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>time_detector_real</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M675,-94C675,-94 529,-94 529,-94 523,-94 517,-88 517,-82 517,-82 517,-42 517,-42 517,-36 523,-30 529,-30 529,-30 675,-30 675,-30 681,-30 687,-36 687,-42 687,-42 687,-82 687,-82 687,-88 681,-94 675,-94\"/>\n",
       "<text text-anchor=\"start\" x=\"528\" y=\"-72.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">time_detector_real</text>\n",
       "<text text-anchor=\"start\" x=\"580.5\" y=\"-44.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">Series</text>\n",
       "</g>\n",
       "<!-- time_detector_real&#45;&gt;transform_raw_data -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>time_detector_real&#45;&gt;transform_raw_data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M687.1,-89.15C695.34,-91.81 703.74,-94.53 712.1,-97.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"711.29,-100.64 721.88,-100.39 713.44,-93.98 711.29,-100.64\"/>\n",
       "</g>\n",
       "<!-- transform_raw_data&#45;&gt;save_transform_raw_data -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>transform_raw_data&#45;&gt;save_transform_raw_data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M887.79,-96.97C909.47,-87.75 933.26,-77.62 955.49,-68.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"957.07,-71.3 964.9,-64.16 954.33,-64.86 957.07,-71.3\"/>\n",
       "</g>\n",
       "<!-- transform_raw_data&#45;&gt;split_and_save_daily -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>transform_raw_data&#45;&gt;split_and_save_daily</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M901.3,-129C914.36,-129 927.87,-129 941.12,-129\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"941.19,-132.5 951.19,-129 941.19,-125.5 941.19,-132.5\"/>\n",
       "</g>\n",
       "<!-- speed_detector_real -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>speed_detector_real</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M681,-176C681,-176 523,-176 523,-176 517,-176 511,-170 511,-164 511,-164 511,-124 511,-124 511,-118 517,-112 523,-112 523,-112 681,-112 681,-112 687,-112 693,-118 693,-124 693,-124 693,-164 693,-164 693,-170 687,-176 681,-176\"/>\n",
       "<text text-anchor=\"start\" x=\"522\" y=\"-154.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">speed_detector_real</text>\n",
       "<text text-anchor=\"start\" x=\"580.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"14.00\">Series</text>\n",
       "</g>\n",
       "<!-- avg_speed&#45;&gt;speed_detector_real -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>avg_speed&#45;&gt;speed_detector_real</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M478.73,-144C485.69,-144 493.01,-144 500.46,-144\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"500.69,-147.5 510.69,-144 500.69,-140.5 500.69,-147.5\"/>\n",
       "</g>\n",
       "<!-- timestamp&#45;&gt;time_detector_real -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>timestamp&#45;&gt;time_detector_real</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M479.68,-62C488.27,-62 497.4,-62 506.64,-62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"506.68,-65.5 516.68,-62 506.68,-58.5 506.68,-65.5\"/>\n",
       "</g>\n",
       "<!-- speed_detector_real&#45;&gt;transform_raw_data -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>speed_detector_real&#45;&gt;transform_raw_data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M693.11,-137.49C699.2,-137.05 705.36,-136.6 711.5,-136.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"712.07,-139.62 721.79,-135.41 711.57,-132.64 712.07,-139.62\"/>\n",
       "</g>\n",
       "<!-- _save_transform_raw_data_inputs -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>_save_transform_raw_data_inputs</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"148,-54.5 0,-54.5 0,-9.5 148,-9.5 148,-54.5\"/>\n",
       "<text text-anchor=\"start\" x=\"15\" y=\"-27.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">dataFilename</text>\n",
       "<text text-anchor=\"start\" x=\"114\" y=\"-27.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">str</text>\n",
       "</g>\n",
       "<!-- _save_transform_raw_data_inputs&#45;&gt;save_transform_raw_data -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>_save_transform_raw_data_inputs&#45;&gt;save_transform_raw_data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M148.25,-22.05C218.95,-13.32 329.1,-2 425,-2 425,-2 425,-2 603,-2 710.21,-2 831.86,-11.08 919.62,-19.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"919.33,-22.73 929.61,-20.19 919.98,-15.77 919.33,-22.73\"/>\n",
       "</g>\n",
       "<!-- _save_transform_raw_data_inputs&#45;&gt;read_raw_data -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>_save_transform_raw_data_inputs&#45;&gt;read_raw_data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M133.98,-54.59C138.72,-56.41 143.44,-58.24 148,-60 158.57,-64.09 169.71,-68.43 180.68,-72.7\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"179.66,-76.06 190.25,-76.44 182.21,-69.54 179.66,-76.06\"/>\n",
       "</g>\n",
       "<!-- _sensor_info_inputs -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>_sensor_info_inputs</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"341,-330.5 177,-330.5 177,-285.5 341,-285.5 341,-330.5\"/>\n",
       "<text text-anchor=\"start\" x=\"192\" y=\"-303.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">sensorFilename</text>\n",
       "<text text-anchor=\"start\" x=\"307\" y=\"-303.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">str</text>\n",
       "</g>\n",
       "<!-- _sensor_info_inputs&#45;&gt;sensor_info -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>_sensor_info_inputs&#45;&gt;sensor_info</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M341.05,-308C347.32,-308 353.59,-308 359.73,-308\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"359.92,-311.5 369.92,-308 359.92,-304.5 359.92,-311.5\"/>\n",
       "</g>\n",
       "<!-- input -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>input</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"103.5,-164.5 44.5,-164.5 44.5,-127.5 103.5,-127.5 103.5,-164.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"74\" y=\"-142.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">input</text>\n",
       "</g>\n",
       "<!-- function -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>function</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M102,-109.5C102,-109.5 46,-109.5 46,-109.5 40,-109.5 34,-103.5 34,-97.5 34,-97.5 34,-84.5 34,-84.5 34,-78.5 40,-72.5 46,-72.5 46,-72.5 102,-72.5 102,-72.5 108,-72.5 114,-78.5 114,-84.5 114,-84.5 114,-97.5 114,-97.5 114,-103.5 108,-109.5 102,-109.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"74\" y=\"-87.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">function</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x79dcbdd7a410>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hamilton import driver\n",
    "import features_import_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = {\n",
    "        \"dataFilename\": \"test_radar_data\",  # or any other file name (without .csv)\n",
    "        \"sensorFilename\": \"sensor_info\"\n",
    "    }\n",
    "    \n",
    "    dr = driver.Builder().with_modules(features_import_data).build()\n",
    "\n",
    "    gr = dr.display_all_functions(\n",
    "    # \"graph.png\", # create image if running locally\n",
    "    show_legend=True,\n",
    "    orient=\"LR\",\n",
    "    deduplicate_inputs=True,\n",
    "    )\n",
    "    \n",
    "    # Save as raw SVG\n",
    "svg_content = gr.pipe(format='svg').decode('utf-8')\n",
    "\n",
    "# Wrap in HTML\n",
    "html_content = f\"\"\"\n",
    "<html>\n",
    "  <body>\n",
    "    {svg_content}\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "with open(\"graph.html\", \"w\") as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "gr\n",
    "\n",
    "   # print(\"Daily files saved:\", results[\"split_and_save_daily\"])\n",
    "   # print(\"Unmapped node_ids:\", results[\"unmapped_node_ids\"])\n",
    "   # print(\"Duration of the data:\", results[\"duration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "916a02aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/kaveh/Hornsgatan/notebook\n",
      "Current directory: /home/kaveh/Hornsgatan/notebook\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "\n",
    "# Replace with your target path\n",
    "#os.chdir(\"../../\")\n",
    "\n",
    "# Confirm the current directory\n",
    "print(\"Current directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "610c9ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/kaveh/Hornsgatan\n",
      "Current directory: /home/kaveh/Hornsgatan\n",
      "Current directory: /home/kaveh/Hornsgatan\n",
      "data/transform_raw_data/test_radar_data_out.csv\n",
      "  detector_id  time_detector_real  speed_detector_real\n",
      "0      w2e_in          1577836782                   27\n",
      "1     e2w_out          1577836785                   32\n",
      "2      w2e_in          1577836785                   28\n",
      "3      w2e_in          1577836787                   27\n",
      "4      w2e_in          1577836788                   23\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "\n",
    "os.chdir(\"/home/kaveh/Hornsgatan/\")\n",
    "import importlib\n",
    "from hamilton import driver, base\n",
    "from src.hamilton import features_import_data\n",
    "\n",
    "# this will reload an already imported module\n",
    "importlib.reload(features_import_data)\n",
    "\n",
    "\n",
    "# Confirm the current directory\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "\n",
    "# Replace with your target path\n",
    "#os.chdir(\".\")\n",
    "\n",
    "# Confirm the current directory\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = {\n",
    "        \"dataFilename\": \"test_radar_data\",  # or any other file name (without .csv)\n",
    "        \"sensorFilename\": \"sensor_info\"\n",
    "    }\n",
    "    \n",
    "    outputs = [\n",
    "        \"transform_raw_data\",\n",
    "        \"save_transform_raw_data\",\n",
    "    ]\n",
    "    dr = driver.Driver(config, features_import_data)\n",
    "    dr = (\n",
    "      driver.Builder()\n",
    "        .with_config(config)  # we don't have any configuration or invariant data for this example.\n",
    "        .with_modules(features_import_data)  # we need to tell hamilton where to load function definitions from\n",
    "        .with_adapters(base.DictResult)  # we want a pandas dataframe as output\n",
    "        .build()\n",
    "    )\n",
    "    results = dr.execute(outputs)\n",
    "    print(results[\"save_transform_raw_data\"])\n",
    "    print(results[\"transform_raw_data\"].head(5))\n",
    "\n",
    "    #print(\"Extended data saved to:\", results[\"timestamp_v2\"])\n",
    "    #print(results[\"transform_raw_data\"])\n",
    "    #print(results[\"transform_raw_data\"].head(5))\n",
    "\n",
    "\n",
    "   # print(\"Daily files saved:\", results[\"split_and_save_daily\"])\n",
    "   # print(\"Unmapped node_ids:\", results[\"unmapped_node_ids\"])\n",
    "   # print(\"Duration of the data:\", results[\"duration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c43a01a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            spend  signups  avg_3wk_spend  acquisition_cost\n",
      "2022-01-02     10        1            NaN               NaN\n",
      "2022-01-09     10       10            NaN               NaN\n",
      "2022-01-16     20       50      13.333333          0.266667\n",
      "2022-01-23     40      100      23.333333          0.233333\n",
      "2022-01-30     40      200      33.333333          0.166667\n",
      "2022-02-06     50      400      43.333333          0.108333\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Replace with your target path\n",
    "#os.chdir(\"/home/kaveh/Hornsgatan/src/hamilton/\")\n",
    "# We add this to speed up running things if you have a lot in your python environment.\n",
    "from hamilton import registry; registry.disable_autoload()\n",
    "from hamilton import driver, base\n",
    "import my_functions  # we import the module here!\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(stream=sys.stdout)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Instantiate a common spine for your pipeline\n",
    "    index = pd.date_range(\"2022-01-01\", periods=6, freq=\"w\")\n",
    "    initial_columns = {  # load from actuals or wherever -- this is our initial data we use as input.\n",
    "        # Note: these do not have to be all series, they could be scalar inputs.\n",
    "        'signups': pd.Series([1, 10, 50, 100, 200, 400], index=index),\n",
    "        'spend': pd.Series([10, 10, 20, 40, 40, 50], index=index),\n",
    "    }\n",
    "    dr = (\n",
    "      driver.Builder()\n",
    "        .with_config({})  # we don't have any configuration or invariant data for this example.\n",
    "        .with_modules(my_functions)  # we need to tell hamilton where to load function definitions from\n",
    "        .with_adapters(base.PandasDataFrameResult())  # we want a pandas dataframe as output\n",
    "        .build()\n",
    "    )\n",
    "    # we need to specify what we want in the final dataframe (these could be function pointers).\n",
    "    output_columns = [\n",
    "        'spend',\n",
    "        'signups',\n",
    "        'avg_3wk_spend',\n",
    "        'acquisition_cost',\n",
    "    ]\n",
    "    # let's create the dataframe!\n",
    "    df = dr.execute(output_columns, inputs=initial_columns)\n",
    "    dr.display_all_functions(\"dag_2.png\")  # outputs a file dag.png\n",
    "\n",
    "    # `pip install sf-hamilton[visualization]` earlier you can also do\n",
    "    #dr.visualize_execution(output_columns,'./my_dag.png', inputs=initial_columns)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438fde54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd32e272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_dataflow.py\n",
    "def A() -> int:\n",
    "    \"\"\"Constant value 35\"\"\"\n",
    "    return 35\n",
    "\n",
    "# ... more functions\n",
    "\n",
    "# is True when calling `python my_dataflow.py`\n",
    "if __name__ == \"__main__\":\n",
    "    from hamilton import driver\n",
    "    # __main__ refers to the file itself\n",
    "    # and yes, a file can import itself as a module!\n",
    "    import __main__\n",
    "\n",
    "    dr = driver.Builder().with_modules(__main__).build()\n",
    "    dr.display_all_functions(\"dag_dag.png\")\n",
    "    dr.execute([\"A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de6cfd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/kaveh/Hornsgatan\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'unix_epoch_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3343124/597787054.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"id\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mf\"{x}_{detector}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unix_epoch_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"detector_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"unix_epoch_time\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"avg_speed\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0mpostfix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{detector}_{date}_{number}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/calib_venv/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   6754\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6755\u001b[0m             \u001b[0;31m# len(by) == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6757\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6758\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6760\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6761\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/calib_venv/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'unix_epoch_time'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "Hornsgatan_Home = \"/home/kaveh/Hornsgatan/\"\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "\n",
    "\n",
    "os.chdir(Hornsgatan_Home)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Calibration Algorithm for One Detector\n",
    "\n",
    "This script calibrates vehicle departure times and speeds in a SUMO simulation\n",
    "to match observed detector data. It iteratively adjusts each vehicle's\n",
    "departure and speed until the simulated detector readings converge to the\n",
    "measured values.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Steps\n",
    "\n",
    "1. **Load and preprocess detector data.**\n",
    "2. **Initialize vehicle trips** with estimated depart times and speeds.\n",
    "3. **Generate SUMO route and configuration files.**\n",
    "4. **For each vehicle:**\n",
    "    - Run SUMO simulation.\n",
    "    - Adjust depart time and speed factor based on detector errors.\n",
    "    - Repeat until convergence or max iterations.\n",
    "5. **Save calibrated results.**\n",
    "\n",
    "---\n",
    "\n",
    "## Speed Units\n",
    "\n",
    "- **All speeds are in meters per second (m/s).**\n",
    "\n",
    "---\n",
    "\n",
    "## Speed Factor\n",
    "\n",
    "- The `speed_factor` is a multiplier applied to the vehicles maximum speed (`maxspeed`) in SUMO.\n",
    "- The actual departure speed (`departSpeed`) is calculated as:  \n",
    "  `departSpeed = speed_factor * maxspeed`\n",
    "- **Range of speed factor in this algorithm:**  \n",
    "  - **Minimum:** `0.9`  \n",
    "  - **Maximum:** `3.0`\n",
    "- **How it is updated:**\n",
    "    - If the simulated speed at the detector is **too high** (`speed_error > 1`), the speed factor is **decreased** by `0.01`, but not below `0.9`.\n",
    "    - If the simulated speed is **too low** (`speed_error < -0.5`), the speed factor is **increased** by `0.1`, but not above `3.0`.\n",
    "- **Limitation:**  \n",
    "  - SUMO may not handle `speed_factor` values less than 1.0 as expected, and very low values can cause unrealistic or unstable simulation behavior.\n",
    "  - The calibration loop increases or decreases `speed_factor` to minimize the difference between simulated and real detector speeds.\n",
    "\n",
    "---\n",
    "\n",
    "## Iteration and Convergence Parameters\n",
    "\n",
    "- **Maximum number of iterations per vehicle:**  \n",
    "  - `iteration = 30` (configurable in the script)\n",
    "- **Convergence conditions:**  \n",
    "  - The calibration loop stops early if both of the following are satisfied:\n",
    "    - `abs(time_error) <= 2` (the difference between simulated and real detector times is less than or equal to 2 seconds)\n",
    "    - `abs(speed_error) <= 1` (the difference between simulated and real detector speeds is# Calibration Algorithm for One Detector\n",
    "\n",
    "This script calibrates vehicle departure times and speeds in a SUMO simulation\n",
    "to match observed detector data. It iteratively adjusts each vehicle's\n",
    "departure and speed until the simulated detector readings converge to the\n",
    "measured values.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Steps\n",
    "\n",
    "1. **Load and preprocess detector data.**\n",
    "2. **Initialize vehicle trips** with estimated depart times and speeds.\n",
    "3. **Generate SUMO route and configuration files.**\n",
    "4. **For each vehicle:**\n",
    "    - Run SUMO simulation.\n",
    "    - Adjust depart time and speed factor based on detector errors.\n",
    "    - Repeat until convergence or max iterations.\n",
    "5. **Save calibrated results.**\n",
    "\n",
    "---\n",
    "\n",
    "## Speed Units\n",
    "\n",
    "- **All speeds are in meters per second (m/s).**\n",
    "\n",
    "---\n",
    "\n",
    "## Speed Factor\n",
    "\n",
    "- The `speed_factor` is a multiplier applied to the vehicles maximum speed (`maxspeed`) in SUMO.\n",
    "- The actual departure speed (`departSpeed`) is calculated as:  \n",
    "  `departSpeed = speed_factor * maxspeed`\n",
    "- **Range of speed factor in this algorithm:**  \n",
    "  - **Minimum:** `0.9`  \n",
    "  - **Maximum:** `3.0`\n",
    "- **How it is updated:**\n",
    "    - If the simulated speed at the detector is **too high** (`speed_error > 1`), the speed factor is **decreased** by `0.01`, but not below `0.9`.\n",
    "    - If the simulated speed is **too low** (`speed_error < -0.5`), the speed factor is **increased** by `0.1`, but not above `3.0`.\n",
    "- **Limitation:**  \n",
    "  - SUMO may not handle `speed_factor` values less than 1.0 as expected, and very low values can cause unrealistic or unstable simulation behavior.\n",
    "  - The calibration loop increases or decreases `speed_factor` to minimize the difference between simulated and real detector speeds.\n",
    "\n",
    "---\n",
    "\n",
    "## Iteration and Convergence Parameters\n",
    "\n",
    "- **Maximum number of iterations per vehicle:**  \n",
    "  - `iteration = 30` (configurable in the script)\n",
    "- **Convergence conditions:**  \n",
    "  - The calibration loop stops early if both of the following are satisfied:\n",
    "    - `abs(time_error) <= 2` (the difference between simulated and real detector times is less than or equal to 2 seconds)\n",
    "    - `abs(speed_error) <= 1` (the difference between simulated and real detector speeds is\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import logging\n",
    "import traci\n",
    "import sumolib\n",
    "from math import ceil\n",
    "\n",
    "# --- Parameters ---\n",
    "date = '2020-01-01'\n",
    "detector = 'w2e_in'\n",
    "path = \"data/calibration_internediate_data/\"\n",
    "pathout = \"data/calibration_data/\"\n",
    "pathin = \"data/daily_splitted_data/\"\n",
    "iteration = 30\n",
    "\n",
    "if detector in ['e2w_out', 'e2w_in']:\n",
    "    maxspeed = 8.33\n",
    "else:\n",
    "    maxspeed = 13.89\n",
    "\n",
    "\n",
    "# --- Load and preprocess data ---\n",
    "data = pd.read_csv(f'{pathin}data_{date}.csv')\n",
    "data = data[data['detector_id'] == detector]\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.reset_index(inplace=True)\n",
    "data.rename(columns={\"index\": \"id\"}, inplace=True)\n",
    "data[\"id\"] = data[\"id\"].apply(lambda x: f\"{x}_{detector}\")\n",
    "data.sort_values(by=['unix_epoch_time'], inplace=True)\n",
    "number = len(data)\n",
    "df = data[[\"id\", \"detector_id\", \"unix_epoch_time\", \"avg_speed\"]].head(number)\n",
    "postfix = f\"{detector}_{date}_{number}\"\n",
    "\n",
    "# --- Detector and route dictionaries ---\n",
    "detector2lane = {\n",
    "    \"e2w_out\": \"1285834640_0\",\n",
    "    \"e2w_in\": \"1285834640_1\",\n",
    "    \"w2e_out\": \"151884974#0_0\",\n",
    "    \"w2e_in\": \"151884974#0_1\",\n",
    "}\n",
    "detector2laneN = {\n",
    "    \"e2w_out\": 0,\n",
    "    \"e2w_in\": 1,\n",
    "    \"w2e_out\": 0,\n",
    "    \"w2e_in\": 1,\n",
    "}\n",
    "detector2from = {\n",
    "    \"e2w_out\": \"24225358#0\",\n",
    "    \"e2w_in\": \"24225358#0\",\n",
    "    \"w2e_out\": \"151884975#0\",\n",
    "    \"w2e_in\": \"151884975#0\",\n",
    "}\n",
    "detector2to = {\n",
    "    \"e2w_out\": \"1243253622#0\",\n",
    "    \"e2w_in\": \"1243253622#0\",\n",
    "    \"w2e_out\": \"151884974#0\",\n",
    "    \"w2e_in\": \"151884974#0\",\n",
    "}\n",
    "detector2route = {\n",
    "    \"e2w_out\": \"24225358#0 1285834640 110107986#2 1243253630#0 98438064#0 1243253622#0\",\n",
    "    \"e2w_in\": \"24225358#0 1285834640 110107986#2 1243253630#0 98438064#0 1243253622#0\",\n",
    "    \"w2e_out\": \"151884975#0 1080999537#0 151884977#0 151884977#4 151884974#0\",\n",
    "    \"w2e_in\": \"151884975#0 1080999537#0 151884977#0 151884977#4 151884974#0\",\n",
    "}\n",
    "\n",
    "# Combine dictionaries into a DataFrame for easy access\n",
    "dataframes = {\n",
    "    \"detector2from\": pd.DataFrame.from_dict(detector2from, orient=\"index\", columns=[\"from\"]),\n",
    "    \"detector2lane\": pd.DataFrame.from_dict(detector2lane, orient=\"index\", columns=[\"lane\"]),\n",
    "    \"detector2laneN\": pd.DataFrame.from_dict(detector2laneN, orient=\"index\", columns=[\"laneN\"]),\n",
    "    \"detector2route\": pd.DataFrame.from_dict(detector2route, orient=\"index\", columns=[\"route\"]),\n",
    "    \"detector2to\": pd.DataFrame.from_dict(detector2to, orient=\"index\", columns=[\"to\"]),\n",
    "}\n",
    "combined_df = pd.concat(dataframes.values(), axis=1)\n",
    "\n",
    "# --- Generate induction loop XML files ---\n",
    "inductionLoop_filename_xml = f\"{path}inductionLoop_{postfix}.xml\"\n",
    "inductionLoop_filename_add = f\"{path}inductionLoop_{postfix}.add.xml\"\n",
    "instantInductionLoop_filename_xml = f\"{path}instantInductionLoop_{postfix}.xml\"\n",
    "instantInductionLoop_filename_add = f\"{path}instantInductionLoop_{postfix}.add.xml\"\n",
    "\n",
    "def write_induction_loop_files():\n",
    "    # Instant induction loop\n",
    "    instant_induction_loops = [\n",
    "        {\"id\": detector, \"lane\": detector2lane[detector], \"pos\": \"1\", \"file\": instantInductionLoop_filename_xml},\n",
    "    ]\n",
    "    root = ET.Element(\"additional\")\n",
    "    for loop in instant_induction_loops:\n",
    "        ET.SubElement(root, \"instantInductionLoop\", loop)\n",
    "    xml_string = ET.tostring(root, encoding=\"unicode\").replace(\"<additional>\", \"<additional>\\n\").replace(\"/>\", \"/>\\n\")\n",
    "    with open(instantInductionLoop_filename_add, \"w\") as file:\n",
    "        file.write(xml_string)\n",
    "\n",
    "    # Standard induction loop\n",
    "    induction_loops = [\n",
    "        {\"id\": detector, \"lane\": detector2lane[detector], \"pos\": \"1\", \"period\": \"1\", \"file\": inductionLoop_filename_xml},\n",
    "    ]\n",
    "    root = ET.Element(\"additional\")\n",
    "    for loop in induction_loops:\n",
    "        ET.SubElement(root, \"inductionLoop\", loop)\n",
    "    xml_string = ET.tostring(root, encoding=\"unicode\").replace(\"<additional>\", \"<additional>\\n\").replace(\"/>\", \"/>\\n\")\n",
    "    with open(inductionLoop_filename_add, \"w\") as file:\n",
    "        file.write(xml_string)\n",
    "\n",
    "write_induction_loop_files()\n",
    "\n",
    "# --- Initialize trips ---\n",
    "def trips_initializing(df, E2S_time=28, W2S_time=51):\n",
    "    trips = df.copy()\n",
    "    trips['depart'] = trips['unix_epoch_time'].copy()\n",
    "    trips['depart'] = trips.apply(lambda row: row[\"unix_epoch_time\"] - E2S_time if row['detector_id'][0] == 'e' else row[\"unix_epoch_time\"] - W2S_time, axis=1)\n",
    "    trips['from'] = trips['detector_id'].apply(lambda x: \"24225358#0\" if x[0] == 'e' else \"151884975#0\")\n",
    "    trips['to'] = trips['detector_id'].apply(lambda x: \"1243253622#0\" if x[0] == 'e' else \"151884974#0\")\n",
    "    trips['departLane'] = trips['detector_id'].apply(lambda x: \"0\" if x[-1] == 't' else \"1\")\n",
    "    trips[\"departSpeed\"] = 0\n",
    "    trips[\"avg_speed\"] = trips[\"avg_speed\"].apply(lambda x: x / 3.6)\n",
    "    trips.sort_values(by=[\"depart\"], inplace=True)\n",
    "    return trips\n",
    "\n",
    "trips = trips_initializing(df)\n",
    "trips.to_csv(f\"trips_{postfix}.csv\", index=False)\n",
    "\n",
    "# --- Generate SUMO route file ---\n",
    "def route_creating(trips, routes_dict):\n",
    "    def convert_row(row, routes_dict=routes_dict, departPos=\"0\", arrivalPos=\"max\"):\n",
    "        return (\n",
    "            f'\\n<vehicle id=\"{row.id}\" depart=\"{row.depart}\" departLane=\"{row.departLane}\" '\n",
    "            f'departSpeed=\"{row.departSpeed}\" departPos=\"{departPos}\" arrivalPos=\"{arrivalPos}\">'\n",
    "            f'\\n    <route edges=\"{routes_dict[row.detector_id]}\"/>\\n</vehicle>'\n",
    "        )\n",
    "    routes = trips.copy()\n",
    "    text0 = '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n\\n\\n'\n",
    "    text1 = '<routes xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:noNamespaceSchemaLocation=\"http://sumo.dlr.de/xsd/routes_file.xsd\">'\n",
    "    text2 = ''.join(routes.apply(convert_row, axis=1))\n",
    "    text3 = '\\n</routes>'\n",
    "    with open(f\"routes_{postfix}.xml\", 'w') as myfile:\n",
    "        myfile.write(text0 + text1 + text2 + text3)\n",
    "\n",
    "route_creating(trips, combined_df[\"route\"].to_dict())\n",
    "\n",
    "# --- Generate SUMO configuration file ---\n",
    "route_file_name = f\"routes_{postfix}.xml\"\n",
    "trips_file_name = f\"trips_{postfix}.csv\"\n",
    "start_time = trips[\"depart\"].min()\n",
    "network_file = \"../../map/Hornsgatan_v2.net.xml\"\n",
    "additional_file = f\"inductionLoop_{postfix}.add.xml\"\n",
    "additional_file_2 = f\"instantInductionLoop_{postfix}.add.xml\"\n",
    "config_file_name = f\"simulation_{postfix}.sumo.cfg\"\n",
    "\n",
    "config_content = f\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<configuration xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:noNamespaceSchemaLocation=\"http://sumo.dlr.de/xsd/sumoConfiguration.xsd\">\n",
    "    <input>\n",
    "        <net-file value=\"{network_file}\"/>\n",
    "        <additional-files value=\"{additional_file},{additional_file_2}\"/>\n",
    "    </input>\n",
    "    <processing>\n",
    "        <default.speeddev value=\"0\"/>\n",
    "    </processing>\n",
    "    <time>\n",
    "        <begin value=\"{start_time}\"/>\n",
    "    </time>\n",
    "    <random>\n",
    "        <seed value=\"13\"/>\n",
    "    </random>\n",
    "    <report>\n",
    "        <no-step-log value=\"true\"/>\n",
    "        <no-warnings value=\"true\"/>\n",
    "    </report>\n",
    "</configuration>\n",
    "\"\"\"\n",
    "\n",
    "with open(config_file_name, \"w\") as config_file:\n",
    "    config_file.write(config_content)\n",
    "\n",
    "print(f\"Configuration file '{config_file_name}' created successfully.\")\n",
    "\n",
    "# --- Main calibration loop ---\n",
    "# To improve speed, you can comment out or remove the logging lines below.\n",
    "# If you want to keep only error logs, adjust the logging level accordingly.\n",
    "\n",
    "# Configure logging (comment out to improve speed)\n",
    "logfile_name = f\"{path}simulation_{postfix}.log\"\n",
    "logging.basicConfig(\n",
    "    filename=logfile_name,\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "logging.info(\"Simulation started.\")\n",
    "\n",
    "trips[\"departSpeed\"] = maxspeed\n",
    "trips[\"speed_factor\"] = 1\n",
    "sumo_binary = \"sumo\"\n",
    "\n",
    "if traci.isLoaded():\n",
    "    traci.close()\n",
    "traci.start([sumo_binary, \"-c\", config_file_name, \"--begin\", str(trips[\"depart\"][0])])#, \"--threads\", \"1\"])\n",
    "traci.route.add(f\"{detector}_route\", combined_df.loc[detector][\"route\"].split())\n",
    "traci.simulation.saveState(f\"simulation_{postfix}_next.sumo.state\")\n",
    "traci.simulation.saveState(f\"simulation_{postfix}.sumo.state\")\n",
    "\n",
    "#lasttrips = []\n",
    "mylog = []\n",
    "step = 0\n",
    "\n",
    "for index, row in trips.iterrows():\n",
    "    traci.simulation.loadState(f\"simulation_{postfix}_next.sumo.state\")\n",
    "    traci.simulation.saveState(f\"simulation_{postfix}.sumo.state\")\n",
    "\n",
    "    # Logging can be commented out for speed\n",
    "    logging.info(f\"Processing vehicle ID: {row['id']}\")\n",
    "    #logging.info(f\"Initial depart: {row['depart']}, departSpeed: {row['departSpeed']}, speed_factor: {row['speed_factor']}\")\n",
    "    row_dict = row.to_dict()\n",
    "    #logging.info(f\"Row data: {row_dict}\")\n",
    "\n",
    "    step += 1\n",
    "    time_error = 10\n",
    "    speed_error = 10\n",
    "    count = 0\n",
    "    speed_factor = 1\n",
    "    prow = row.copy()\n",
    "\n",
    "    while (count < iteration) and ((abs(time_error) > 2) or abs(speed_error) > 1):\n",
    "        try:\n",
    "            traci.simulation.loadState(f\"simulation_{postfix}.sumo.state\")\n",
    "        except traci.FatalTraCIError as e:\n",
    "            print(\"Error loading simulation state:\", e)\n",
    "            logging.error(f\"Error loading simulation state: {e}\")\n",
    "            traci.close()\n",
    "            raise\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        # Remove the vehicle if it exists\n",
    "        if row['id'] in traci.vehicle.getIDList():\n",
    "            traci.vehicle.remove(row['id'])\n",
    "\n",
    "        # Adjust depart time for consecutive vehicles\n",
    "        if len(mylog) > 0 and count == 1:\n",
    "            row[\"depart\"] = mylog[-1][\"depart\"] + (row[\"unix_epoch_time\"] - mylog[-1][\"time_detector_real\"])\n",
    "\n",
    "        #logging.info(f\"Updated depart: {row['depart']}, departSpeed: {row['departSpeed']}, speed_factor: {row['speed_factor']}\")\n",
    "\n",
    "        try:\n",
    "            traci.vehicle.addFull(\n",
    "                vehID=row['id'],\n",
    "                routeID=f\"{row['detector_id']}_route\",\n",
    "                depart=row[\"depart\"],\n",
    "                departPos=\"0\",\n",
    "                departSpeed=\"max\",    #change o to max\n",
    "                departLane=row[\"departLane\"],\n",
    "            )\n",
    "            traci.vehicle.setSpeedMode(row['id'], 95)\n",
    "            traci.vehicle.setSpeed(row['id'], row[\"speed_factor\"] * maxspeed)\n",
    "            row[\"departSpeed\"] = row[\"speed_factor\"] * maxspeed\n",
    "            traci.vehicle.setLaneChangeMode(row['id'], 0)\n",
    "        except traci.TraCIException as e:\n",
    "            print(f\"Error adding vehicle {row['id']}:\", e)\n",
    "            logging.error(f\"Error adding vehicle {row['id']}: {e}\")\n",
    "            traci.close()\n",
    "            raise\n",
    "\n",
    "        traci.vehicle.setSpeedFactor(row[\"id\"], row[\"speed_factor\"])\n",
    "        #logging.info(f\"start iteration in time {traci.simulation.getTime()}\")\n",
    "\n",
    "        while traci.simulation.getMinExpectedNumber() > 0:\n",
    "            if traci.simulation.getTime() == int(row[\"depart\"]) + 1:\n",
    "                #logging.info(f\" In time {traci.simulation.getTime()} added simulation_{postfix}_next.sumo.state\")\n",
    "                traci.vehicle.setSpeed(row[\"id\"], row[\"departSpeed\"])\n",
    "                traci.vehicle.setLaneChangeMode(row[\"id\"], 0)\n",
    "                traci.simulation.saveState(f\"simulation_{postfix}_next.sumo.state\")\n",
    "            traci.simulationStep()\n",
    "\n",
    "            for veh_id in traci.simulation.getDepartedIDList():\n",
    "                traci.vehicle.setLaneChangeMode(veh_id, 0)\n",
    "            vehicles = traci.inductionloop.getLastStepVehicleIDs(detector)\n",
    "            #if vehicles and vehicles[0] != row[\"id\"] and row['id'] == \"3e2w_out\":\n",
    "            #    logging.info(vehicles, row[\"id\"])\n",
    "            #    print(vehicles, row[\"id\"])\n",
    "            if vehicles and vehicles[0] == row[\"id\"]:\n",
    "                veh_id, veh_length, entry_time, exit_time, vType = traci.inductionloop.getVehicleData(detector)[0]\n",
    "                speed = traci.inductionloop.getLastStepMeanSpeed(detector)\n",
    "                time = round(entry_time - 1, 2)\n",
    "                #print(f\"veh_id: {veh_id} | Time: {time} s  | Speed: {speed:.2f} m/s\")\n",
    "                #logging.info(f\"traci_time: {traci.simulation.getTime()} | veh_id: {veh_id} | Time: {time} s  | Speed: {speed:.2f} m/s\")\n",
    "                # Calculate the time and speed errors\n",
    "                time_error = time - row[\"unix_epoch_time\"]\n",
    "                speed_error = speed - row[\"avg_speed\"]\n",
    "                #print(\"depart: \", row[\"depart\"], \"departSpeed: \",\n",
    "                #      row[\"departSpeed\"], \"speed_factor: \", row[\"speed_factor\"], \"time_error : \", time_error,\n",
    "                #      \"speed_error : \", speed_error)\n",
    "                #logging.info(f\"depart: {row['depart']}, departSpeed: {row['departSpeed']}, speed_factor: {row['speed_factor']}, time_error: {time_error}, speed_error: {speed_error}\")\n",
    "\n",
    "                prow = row.copy()\n",
    "                row[\"depart\"] = row[\"depart\"] - (time - row[\"unix_epoch_time\"])\n",
    "                if len(mylog) > 0 and row[\"depart\"] <= mylog[-1][\"depart\"]:\n",
    "                    row[\"depart\"] = mylog[-1][\"depart\"] + 1\n",
    "\n",
    "                if speed_error > 0 and speed_error > 1:\n",
    "                    row[\"speed_factor\"] = max(.9, row[\"speed_factor\"] - 0.01)\n",
    "                if speed_error <= 0 and speed_error < -.5:\n",
    "                    row[\"speed_factor\"] = min(3, row[\"speed_factor\"] + 0.1)\n",
    "\n",
    "                row[\"departSpeed\"] = maxspeed\n",
    "                if row['speed_factor'] < 1:\n",
    "                    row[\"departSpeed\"] = maxspeed * row[\"speed_factor\"]\n",
    "                if row['speed_factor'] > 1:\n",
    "                    row[\"departSpeed\"] = maxspeed * row[\"speed_factor\"]\n",
    "\n",
    "                #print(\"next depart: \", row[\"depart\"], \"next SPEED factor: \", row[\"speed_factor\"])\n",
    "                #logging.info(f\"next depart: {row['depart']}, next SPEED factor: {row['speed_factor']}\")\n",
    "                break\n",
    "\n",
    "    # Save the calibrated values back to the DataFrame\n",
    "    #lasttrips.append(row)\n",
    "    mylog.append({\n",
    "        \"veh_id\": prow[\"id\"],\n",
    "        \"time_detector_sim\": time,\n",
    "        \"speed_detector_sim\": speed,\n",
    "        \"speed_factor\": prow[\"speed_factor\"],\n",
    "        \"time_detector_real\": prow[\"unix_epoch_time\"],\n",
    "        \"depart\": prow[\"depart\"],\n",
    "        \"departSpeed\": prow[\"departSpeed\"],\n",
    "        \"speed_detector_real\": prow[\"avg_speed\"]\n",
    "    })\n",
    "\n",
    "if traci.isLoaded():\n",
    "    traci.close()\n",
    "\n",
    "# --- Save results ---\n",
    "#df = pd.DataFrame(lasttrips)\n",
    "#df.to_csv(f\"{path}calibrated_trips_{postfix}.csv\", index=False)\n",
    "\n",
    "log_df = pd.DataFrame(mylog)\n",
    "log_df[\"delta_time\"] = log_df[\"time_detector_sim\"] - log_df[\"time_detector_real\"]\n",
    "log_df[\"delta_speed\"] = log_df[\"speed_detector_sim\"] - log_df[\"speed_detector_real\"]\n",
    "log_df.to_csv(f\"{path}log_{postfix}.csv\", index=False)\n",
    "\n",
    "#print(\"Calibration complete. Results saved.\")\n",
    "\n",
    "# --- Note on Logging ---\n",
    "# To improve running speed, you may comment out or remove the logging configuration and all logging.info/logging.error calls above.\n",
    "# This will reduce disk I/O and speed up the calibration loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4b470a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "detector_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "time_detector_real",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "speed_detector_real",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b9dbed4f-3fd9-4b0a-8f14-f0a6cf153ae1",
       "rows": [
        [
         "0",
         "0_w2e_in",
         "w2e_in",
         "1577836811",
         "33",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "1",
         "1_w2e_in",
         "w2e_in",
         "1577836814",
         "27",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "2",
         "2_w2e_in",
         "w2e_in",
         "1577836815",
         "32",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "3",
         "3_w2e_in",
         "w2e_in",
         "1577836826",
         "40",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "4",
         "4_w2e_in",
         "w2e_in",
         "1577836847",
         "28",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "5",
         "5_w2e_in",
         "w2e_in",
         "1577836849",
         "24",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "6",
         "6_w2e_in",
         "w2e_in",
         "1577836880",
         "36",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "7",
         "7_w2e_in",
         "w2e_in",
         "1577836884",
         "27",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "8",
         "8_w2e_in",
         "w2e_in",
         "1577836906",
         "35",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "9",
         "9_w2e_in",
         "w2e_in",
         "1577836932",
         "33",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "10",
         "10_w2e_in",
         "w2e_in",
         "1577836934",
         "27",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "11",
         "11_w2e_in",
         "w2e_in",
         "1577836936",
         "31",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "12",
         "12_w2e_in",
         "w2e_in",
         "1577836939",
         "23",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "13",
         "13_w2e_in",
         "w2e_in",
         "1577836943",
         "38",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "14",
         "14_w2e_in",
         "w2e_in",
         "1577836945",
         "33",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "15",
         "15_w2e_in",
         "w2e_in",
         "1577836947",
         "28",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "16",
         "16_w2e_in",
         "w2e_in",
         "1577836953",
         "31",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "17",
         "17_w2e_in",
         "w2e_in",
         "1577836960",
         "34",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "18",
         "18_w2e_in",
         "w2e_in",
         "1577836962",
         "32",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "19",
         "19_w2e_in",
         "w2e_in",
         "1577836964",
         "32",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "20",
         "20_w2e_in",
         "w2e_in",
         "1577836978",
         "33",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "21",
         "21_w2e_in",
         "w2e_in",
         "1577837006",
         "42",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "22",
         "22_w2e_in",
         "w2e_in",
         "1577837011",
         "36",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "23",
         "23_w2e_in",
         "w2e_in",
         "1577837013",
         "28",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "24",
         "24_w2e_in",
         "w2e_in",
         "1577837015",
         "30",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "25",
         "25_w2e_in",
         "w2e_in",
         "1577837017",
         "26",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "26",
         "26_w2e_in",
         "w2e_in",
         "1577837020",
         "30",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "27",
         "27_w2e_in",
         "w2e_in",
         "1577837022",
         "31",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "28",
         "28_w2e_in",
         "w2e_in",
         "1577837024",
         "34",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "29",
         "29_w2e_in",
         "w2e_in",
         "1577837025",
         "30",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "30",
         "30_w2e_in",
         "w2e_in",
         "1577837036",
         "40",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "31",
         "31_w2e_in",
         "w2e_in",
         "1577837042",
         "37",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "32",
         "32_w2e_in",
         "w2e_in",
         "1577837064",
         "43",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "33",
         "33_w2e_in",
         "w2e_in",
         "1577837069",
         "39",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "34",
         "34_w2e_in",
         "w2e_in",
         "1577837092",
         "33",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "35",
         "35_w2e_in",
         "w2e_in",
         "1577837095",
         "31",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "36",
         "36_w2e_in",
         "w2e_in",
         "1577837098",
         "29",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "37",
         "37_w2e_in",
         "w2e_in",
         "1577837131",
         "43",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "38",
         "38_w2e_in",
         "w2e_in",
         "1577837133",
         "31",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "39",
         "39_w2e_in",
         "w2e_in",
         "1577837135",
         "38",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "40",
         "40_w2e_in",
         "w2e_in",
         "1577837142",
         "25",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "41",
         "41_w2e_in",
         "w2e_in",
         "1577837146",
         "38",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "42",
         "42_w2e_in",
         "w2e_in",
         "1577837152",
         "30",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "43",
         "43_w2e_in",
         "w2e_in",
         "1577837164",
         "25",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "44",
         "44_w2e_in",
         "w2e_in",
         "1577837181",
         "33",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "45",
         "45_w2e_in",
         "w2e_in",
         "1577837183",
         "28",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "46",
         "46_w2e_in",
         "w2e_in",
         "1577837211",
         "36",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "47",
         "47_w2e_in",
         "w2e_in",
         "1577837212",
         "32",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "48",
         "48_w2e_in",
         "w2e_in",
         "1577837215",
         "39",
         "Wednesday",
         "2020-01-01"
        ],
        [
         "49",
         "49_w2e_in",
         "w2e_in",
         "1577837219",
         "29",
         "Wednesday",
         "2020-01-01"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 10162
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>detector_id</th>\n",
       "      <th>time_detector_real</th>\n",
       "      <th>speed_detector_real</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_w2e_in</td>\n",
       "      <td>w2e_in</td>\n",
       "      <td>1577836811</td>\n",
       "      <td>33</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_w2e_in</td>\n",
       "      <td>w2e_in</td>\n",
       "      <td>1577836814</td>\n",
       "      <td>27</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_w2e_in</td>\n",
       "      <td>w2e_in</td>\n",
       "      <td>1577836815</td>\n",
       "      <td>32</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3_w2e_in</td>\n",
       "      <td>w2e_in</td>\n",
       "      <td>1577836826</td>\n",
       "      <td>40</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4_w2e_in</td>\n",
       "      <td>w2e_in</td>\n",
       "      <td>1577836847</td>\n",
       "      <td>28</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10157</th>\n",
       "      <td>10157_w2e_in</td>\n",
       "      <td>w2e_in</td>\n",
       "      <td>1577923177</td>\n",
       "      <td>32</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10158</th>\n",
       "      <td>10158_w2e_in</td>\n",
       "      <td>w2e_in</td>\n",
       "      <td>1577923179</td>\n",
       "      <td>25</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10159</th>\n",
       "      <td>10159_w2e_in</td>\n",
       "      <td>w2e_in</td>\n",
       "      <td>1577923181</td>\n",
       "      <td>29</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10160</th>\n",
       "      <td>10160_w2e_in</td>\n",
       "      <td>w2e_in</td>\n",
       "      <td>1577923185</td>\n",
       "      <td>36</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10161</th>\n",
       "      <td>10161_w2e_in</td>\n",
       "      <td>w2e_in</td>\n",
       "      <td>1577923193</td>\n",
       "      <td>36</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10162 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id detector_id  time_detector_real  speed_detector_real  \\\n",
       "0          0_w2e_in      w2e_in          1577836811                   33   \n",
       "1          1_w2e_in      w2e_in          1577836814                   27   \n",
       "2          2_w2e_in      w2e_in          1577836815                   32   \n",
       "3          3_w2e_in      w2e_in          1577836826                   40   \n",
       "4          4_w2e_in      w2e_in          1577836847                   28   \n",
       "...             ...         ...                 ...                  ...   \n",
       "10157  10157_w2e_in      w2e_in          1577923177                   32   \n",
       "10158  10158_w2e_in      w2e_in          1577923179                   25   \n",
       "10159  10159_w2e_in      w2e_in          1577923181                   29   \n",
       "10160  10160_w2e_in      w2e_in          1577923185                   36   \n",
       "10161  10161_w2e_in      w2e_in          1577923193                   36   \n",
       "\n",
       "             day        date  \n",
       "0      Wednesday  2020-01-01  \n",
       "1      Wednesday  2020-01-01  \n",
       "2      Wednesday  2020-01-01  \n",
       "3      Wednesday  2020-01-01  \n",
       "4      Wednesday  2020-01-01  \n",
       "...          ...         ...  \n",
       "10157  Wednesday  2020-01-01  \n",
       "10158  Wednesday  2020-01-01  \n",
       "10159  Wednesday  2020-01-01  \n",
       "10160  Wednesday  2020-01-01  \n",
       "10161  Wednesday  2020-01-01  \n",
       "\n",
       "[10162 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b119024a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'my_submodule'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__doc__', '__loader__', '__name__', '__package__', '__spec__', 'maxspeed']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import inspect\n",
    "\n",
    "import types\n",
    "\n",
    "# Create a new empty module-like object\n",
    "my_submodule = types.ModuleType(\"my_submodule\")\n",
    "\n",
    "# Replace with your target path\n",
    "os.chdir(\"/home/kaveh/Hornsgatan/src/hamilton/\")\n",
    "# We add this to speed up running things if you have a lot in your python environment.\n",
    "from hamilton import registry; registry.disable_autoload()\n",
    "from hamilton import driver, base\n",
    "from features_calib import maxspeed,number,postfix,detector_mappings,instant_induction_loop_add_file,raw_data,preprocess_data\n",
    "\n",
    "subdag = [maxspeed,number,postfix,detector_mappings,instant_induction_loop_add_file,raw_data,preprocess_data]\n",
    "\n",
    "subdag\n",
    "my_submodule = types.ModuleType(\"my_submodule\")\n",
    "\n",
    "for func_name in subdag:\n",
    "    setattr(my_submodule, func_name, getattr(func_name))\n",
    "\n",
    "\n",
    "print(my_submodule)\n",
    "dir(my_submodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f36efa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kaveh/Hornsgatan\n",
      "The project path is: /home/kaveh/Hornsgatan\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HORNSGATAN_HOME'] = '/home/kaveh/Hornsgatan'\n",
    "project_path = os.environ.get(\"HORNSGATAN_HOME\")\n",
    "\n",
    "print(project_path)\n",
    "\n",
    "if project_path:\n",
    "    print(f\"The project path is: {project_path}\")\n",
    "else:\n",
    "    print(\"The PROJECT_PATH environment variable is not set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f16ea841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "project_path = os.environ.get(\"HORNSGATAN_HOME\")\n",
    "print(project_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calib_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
